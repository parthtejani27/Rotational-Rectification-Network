{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d8f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = 'F:/dataset'  # Path to the dataset folder\n",
    "destination_dir = 'E:/Updated Dataset'  # Path to the destination folder\n",
    "\n",
    "sets = ['set00','set01','set02','set03','set04','set05']\n",
    "\n",
    "# Create train and test directories in the destination folder\n",
    "train_dir = os.path.join(destination_dir, 'train')\n",
    "test_dir = os.path.join(destination_dir, 'test')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "img_dest_dir = os.path.join(train_dir,'images')\n",
    "annot_dest_dir = os.path.join(train_dir,'annotations')\n",
    "os.makedirs(img_dest_dir, exist_ok=True)\n",
    "os.makedirs(annot_dest_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for set_name in sets:\n",
    "    set_dir = os.path.join(source_dir, set_name)\n",
    "    videos = [f for f in os.listdir(set_dir) if os.path.isdir(os.path.join(set_dir, f))]\n",
    "    for video_name in videos:\n",
    "        video_dir = os.path.join(set_dir, video_name)\n",
    "        img_source_dir = os.path.join(video_dir, 'images')\n",
    "        annot_source_dir = os.path.join(video_dir, 'annotations')\n",
    "        \n",
    "        for img_file in os.listdir(img_source_dir):\n",
    "            img_source_path = os.path.join(img_source_dir, img_file)\n",
    "            img_dest_path = os.path.join(img_dest_dir, set_name + '_' + video_name + '_' + img_file)\n",
    "            shutil.copy(img_source_path, img_dest_path)\n",
    "            annot_dest_path = os.path.join(annot_dest_dir, set_name + '_' + video_name + '_' + img_file[:-4]+'.json')\n",
    "            shutil.copy(annot_source_path, annot_dest_path)\n",
    "            \n",
    "        for annot_file in os.listdir(annot_source_dir):\n",
    "            annot_source_path = os.path.join(annot_source_dir, annot_file)\n",
    "            annot_dest_path = os.path.join(annot_dest_dir, set_name + '_' + video_name + '_' + annot_file)\n",
    "            shutil.copy(annot_source_path, annot_dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e5433e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Rotate function\n",
    "def rotate_image(image, angle):\n",
    "    rotated_image = image.rotate(angle)\n",
    "    rotated_image = np.array(rotated_image)\n",
    "    return rotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ae60814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "training_Path_To_Rotate = \"E:/Updated Dataset/train/images\"\n",
    "testing_Path_To_Rotate = \"E:/Updated Dataset/test/images\"\n",
    "\n",
    "rotated_training_path = \"E:/Updated Dataset/train/rotated_images\"\n",
    "rotated_testing_path = \"E:/Updated Dataset/test/rotated_images\"\n",
    "\n",
    "rotated_train_json_angle_path = \"E:/Updated Dataset/train/angle.json\"\n",
    "rotated_test_json_angle_path = \"E:/Updated Dataset/test/angle.json\"\n",
    "\n",
    "os.makedirs(rotated_training_path, exist_ok=True)\n",
    "os.makedirs(rotated_testing_path, exist_ok=True)\n",
    "\n",
    "rotated_training_angles_dict = []\n",
    "rotated_testing_angles_dict = []\n",
    "\n",
    "for filename in os.listdir(training_Path_To_Rotate):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(training_Path_To_Rotate, filename)\n",
    "        angle = np.random.randint(-90, 91)\n",
    "        rotated_image = rotate_image(np.array(Image.open(image_path).convert('L')), angle)\n",
    "        \n",
    "        rotated_filename = os.path.splitext(filename)[0] + '_rotated_' + str(angle) + '.jpg'\n",
    "        rotated_image_path = os.path.join(rotated_training_path, rotated_filename)\n",
    "        Image.fromarray(rotated_image.astype('uint8')).save(rotated_image_path)\n",
    "        \n",
    "        rotated_training_angles_dict.append([rotated_filename,angle])\n",
    "        \n",
    "\n",
    "    \n",
    "for filename in os.listdir(testing_Path_To_Rotate):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(testing_Path_To_Rotate, filename)\n",
    "        angle = np.random.randint(-90, 91)\n",
    "        rotated_image = rotate_image(np.array(Image.open(image_path).convert('L')), angle)\n",
    "        \n",
    "        rotated_filename = os.path.splitext(filename)[0] + '_rotated_' + str(angle) + '.jpg'\n",
    "        rotated_image_path = os.path.join(rotated_testing_path, rotated_filename)\n",
    "        Image.fromarray(rotated_image.astype('uint8')).save(rotated_image_path)\n",
    "        \n",
    "        rotated_testing_angles_dict.append([rotated_filename,angle])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af1eb716",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_training_angles_dict=pd.DataFrame(rotated_training_angles_dict,columns=[\"Filename\",\"angle\"])\n",
    "rotated_testing_angles_dict=pd.DataFrame(rotated_testing_angles_dict,columns=[\"Filename\",\"angle\"])\n",
    "\n",
    "rotated_training_angles_dict.to_csv(rotated_train_json_angle_path)\n",
    "rotated_testing_angles_dict.to_csv(rotated_test_json_angle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48bc1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "# Load JSON data containing annotations\n",
    "json_path =\"F:/dataset/set00/V000/annotations/I00297.json\"\n",
    "\n",
    "with open(json_path, 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Read the image file\n",
    "image_path = \"E:/Caltech Dataset With Annotation and rotation/train/images/set00_V000_I00297.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Iterate through each annotation\n",
    "for annotation in json_data:\n",
    "    # Extract annotation details (e.g., bounding box coordinates)\n",
    "    x, y, width, height = map(int, annotation['pos'])\n",
    "\n",
    "    # Draw bounding box rectangle on the image\n",
    "    cv2.rectangle(image, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with annotations\n",
    "cv2.imshow('Image with Annotations', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec1cc273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in c:\\users\\parth\\anaconda3\\lib\\site-packages (3.19.0)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-4.23.4-cp39-cp39-win_amd64.whl (422 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.0\n",
      "    Uninstalling protobuf-3.19.0:\n",
      "      Successfully uninstalled protobuf-3.19.0\n",
      "Successfully installed protobuf-4.23.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.4 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.4 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.19.0\n",
      "  Using cached protobuf-3.19.0-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.4\n",
      "    Uninstalling protobuf-4.23.4:\n",
      "      Successfully uninstalled protobuf-4.23.4\n",
      "Successfully installed protobuf-3.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.53.0 requires protobuf>=4.21.6, but you have protobuf 3.19.0 which is incompatible.\n",
      "googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
      "google-cloud-speech 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
      "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\parth\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.30.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.53.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.21)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\parth\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\parth\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8940\\3242351139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install protobuf==3.19.0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install tensorflow'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\tf2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_tf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!pip install --upgrade protobuf\n",
    "!pip install protobuf==3.19.0\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, GlobalMaxPooling2D, Flatten, concatenate, ZeroPadding2D\n",
    "\n",
    "def create_model(input_shape):\n",
    "    # Input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    conv1 = Conv2D(64, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(norm1)\n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    conv2 = Conv2D(128, kernel_size=(3, 3), activation='relu')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Convolutional Layer 3\n",
    "    conv3 = Conv2D(256, kernel_size=(3, 3), activation='relu',padding='same')(pool2)\n",
    "\n",
    "    # Convolutional Layer 4\n",
    "    conv4 = Conv2D(256, kernel_size=(3, 3), activation='relu',padding=\"same\")(conv3)\n",
    "\n",
    "    # Convolutional Layer 5\n",
    "    conv5 = Conv2D(256, kernel_size=(3, 3), activation='relu',padding='same')(conv4)\n",
    "\n",
    "    # # Adjust spatial dimensions of conv3 and conv4\n",
    "    # conv3_pad = ZeroPadding2D(padding=((0, 0), (0, 0)))(conv3)  # Pad conv3 to match conv5\n",
    "    # conv4_pad = ZeroPadding2D(padding=((0, 0), (0, 0)))(conv4)  # Pad conv4 to match conv5\n",
    "\n",
    "    # Concatenate conv3, conv4, and conv5\n",
    "    concat = concatenate([conv3, conv4, conv5])\n",
    "\n",
    "    # Global Pooling\n",
    "    gp_pool = GlobalMaxPooling2D()(concat)\n",
    "\n",
    "    # Flatten\n",
    "    flatten = Flatten()(gp_pool)\n",
    "\n",
    "    # Output layer (Theta)\n",
    "    theta = tf.keras.layers.Dense(units=1, activation='linear')(flatten)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=theta)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (480, 640, 3)  # 480x640 RGB images\n",
    "\n",
    "# Create the model\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5320e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
